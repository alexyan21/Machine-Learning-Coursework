{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Document Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Create your own distance function that, instead of using Euclidean distance, uses Cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disCosine(x, D):\n",
    "    D_norm = np.linalg.norm(D)\n",
    "    x_norm = np.linalg.norm(x)\n",
    "    sims = np.dot(D,x)/(D_norm * x_norm)\n",
    "    dists = 1- sims\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Load the data set, Then, split the data set (the document x term matrix) and set aside 20% for later use (see below). Use the 80% segment for clustering in the next part. The 20% portion must be a random subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### load data\n",
    "DT = pd.read_csv('/Users/Alexkilledme/Desktop/2018SQ/CSC478 - Machine Learning/hw/newsgroups5/matrix.txt',sep=',',header=None)\n",
    "DT = np.array(DT.T)\n",
    "Terms = pd.read_csv('/Users/Alexkilledme/Desktop/2018SQ/CSC478 - Machine Learning/hw/newsgroups5/terms.txt',sep=' ',header=None)\n",
    "Terms = np.array(Terms)\n",
    "Class = pd.read_csv('/Users/Alexkilledme/Desktop/2018SQ/CSC478 - Machine Learning/hw/newsgroups5/classes.txt',sep=' ')\n",
    "Class = Class.iloc[:,1]\n",
    "Class = np.array(Class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(2500, 9328)\n"
     ]
    }
   ],
   "source": [
    "print DT\n",
    "print DT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['aa']\n",
      " ['aargh']\n",
      " ['aaron']\n",
      " ...\n",
      " ['zw']\n",
      " ['zx']\n",
      " ['zz']]\n",
      "(9328, 1)\n"
     ]
    }
   ],
   "source": [
    "print Terms\n",
    "print Terms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 3 4 2]\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "print Class\n",
    "print Class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('There are ', 2500, 'documents')\n",
      "('There are ', 9328, 'terms')\n"
     ]
    }
   ],
   "source": [
    "N_doc_train=DT.shape[0]\n",
    "N_terms=Terms.shape[0]\n",
    "print('There are ',N_doc_train,'documents')\n",
    "print('There are ',N_terms,'terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Alexkilledme/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "### split training and testing data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "DT_train, DT_test, Class_train, Class_test = train_test_split(DT, Class, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 9328)\n",
      "(500, 9328)\n",
      "(2000,)\n",
      "(500,)\n"
     ]
    }
   ],
   "source": [
    "print DT_train.shape\n",
    "print DT_test.shape\n",
    "print Class_train.shape\n",
    "print Class_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Perform Kmeans clustering on the training data. Write a function to display the top N terms in each cluster along with the cluster DF values for each term and the size of the cluster. The cluster DF value for a term t in a cluster C is the percentage of docs in cluster C in which term t appears (so, if a cluster has 500 documents, and term \"game\" appears in 100 of those 500 documents, then DF value of \"game\" in that cluster is 0.2 or 20%). Sort the terms for each cluster in decreasing order of the DF percentage. Here is an example of how this output might look like (here the top 10 terms for 3 of the 5 clusters are displayed in decreasing order of cluster DF values, but the mean frequnecy from the cluster centroid is also shown). [Extra Credit: use your favorite third party tool, ideally with a Python based API, to create a word cloud for each cluster.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the data into TFIDF is using sklearn.feature_extraction.text built-in module\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "NewDTTrain_TFIDF = TfidfTransformer().fit_transform(DT_train).toarray()\n",
    "NewDTTest_TFIDF = TfidfTransformer().fit_transform(DT_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Perform Kmeans clustering on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Alexkilledme/Desktop\n"
     ]
    }
   ],
   "source": [
    "cd \"/Users/Alexkilledme/Desktop/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "from sklearn.cluster import KMeans \n",
    "import kMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'kMeans' from 'kMeans.pyc'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(kMeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D = input Dataset\n",
    "#k = Number of Clusters\n",
    "#Measure = disCosine or disEuclid\n",
    "#top_No_terms = Number of terms in each cluster will be displayed\n",
    "\n",
    "#kMeans_func is used to display the top N terms in each cluster along with\n",
    "#the cluster DF values for each term and percent of Docs include the term.\n",
    "def TopTerms(data, k, NTerms):\n",
    "    centroids, clusters = kMeans.kMeans(mat(data), k, distMeas=disCosine)\n",
    "    for i in range(k):\n",
    "        print 'cluster',i+1,':'\n",
    "        cluster_DT = data[clusters[:,0]==i]\n",
    "        print 'cluster',i+1,' size: ', cluster_DT.shape[0]\n",
    "        cluster_DF = np.array([(cluster_DT.T!=0).sum(1)]).T\n",
    "        term_doc_pc_cluster = cluster_DF/float(cluster_DT.shape[0])\n",
    "        term_doc_pc_cluster = map(list, term_doc_pc_cluster)\n",
    "        term_doc_pc_cluster = [elem[0] for elem in term_doc_pc_cluster]\n",
    "        cluster_DF = [elem[0] for elem in cluster_DF]\n",
    "        a=sorted(zip(Terms, cluster_DF, term_doc_pc_cluster),key=lambda x:x[2],reverse=True)\n",
    "        for elem in a[:NTerms]:\n",
    "            print 'term: ',elem[0]\n",
    "            print 'cluster DF: ',elem[1]\n",
    "            print 'percentage of docs in the cluster where the term appears: ',elem[2],'\\n'\n",
    "        print '\\n'\n",
    "    return  centroids, clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster 1 :\n",
      "cluster 1  size:  382\n",
      "term:  ['subject']\n",
      "cluster DF:  382\n",
      "percentage of docs in the cluster where the term appears:  1.0 \n",
      "\n",
      "term:  ['write']\n",
      "cluster DF:  262\n",
      "percentage of docs in the cluster where the term appears:  0.6858638743455497 \n",
      "\n",
      "term:  ['articl']\n",
      "cluster DF:  201\n",
      "percentage of docs in the cluster where the term appears:  0.5261780104712042 \n",
      "\n",
      "\n",
      "\n",
      "cluster 2 :\n",
      "cluster 2  size:  401\n",
      "term:  ['subject']\n",
      "cluster DF:  401\n",
      "percentage of docs in the cluster where the term appears:  1.0 \n",
      "\n",
      "term:  ['write']\n",
      "cluster DF:  219\n",
      "percentage of docs in the cluster where the term appears:  0.5461346633416458 \n",
      "\n",
      "term:  ['game']\n",
      "cluster DF:  214\n",
      "percentage of docs in the cluster where the term appears:  0.5336658354114713 \n",
      "\n",
      "\n",
      "\n",
      "cluster 3 :\n",
      "cluster 3  size:  392\n",
      "term:  ['subject']\n",
      "cluster DF:  392\n",
      "percentage of docs in the cluster where the term appears:  1.0 \n",
      "\n",
      "term:  ['window']\n",
      "cluster DF:  277\n",
      "percentage of docs in the cluster where the term appears:  0.7066326530612245 \n",
      "\n",
      "term:  ['write']\n",
      "cluster DF:  172\n",
      "percentage of docs in the cluster where the term appears:  0.4387755102040816 \n",
      "\n",
      "\n",
      "\n",
      "cluster 4 :\n",
      "cluster 4  size:  406\n",
      "term:  ['subject']\n",
      "cluster DF:  406\n",
      "percentage of docs in the cluster where the term appears:  1.0 \n",
      "\n",
      "term:  ['write']\n",
      "cluster DF:  260\n",
      "percentage of docs in the cluster where the term appears:  0.6403940886699507 \n",
      "\n",
      "term:  ['on']\n",
      "cluster DF:  230\n",
      "percentage of docs in the cluster where the term appears:  0.5665024630541872 \n",
      "\n",
      "\n",
      "\n",
      "cluster 5 :\n",
      "cluster 5  size:  419\n",
      "term:  ['subject']\n",
      "cluster DF:  419\n",
      "percentage of docs in the cluster where the term appears:  1.0 \n",
      "\n",
      "term:  ['sale']\n",
      "cluster DF:  224\n",
      "percentage of docs in the cluster where the term appears:  0.5346062052505967 \n",
      "\n",
      "term:  ['email']\n",
      "cluster DF:  167\n",
      "percentage of docs in the cluster where the term appears:  0.39856801909307876 \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "centroids, clusters = TopTerms(NewDTTrain_TFIDF, 5, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Using the cluster assignments from Kmeans clustering, compare your 5 clusters to the 5 pre-assigned classes by computing the Completeness and Homogeneity values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split training and testing data\n",
    "from sklearn.cross_validation import train_test_split\n",
    "DT_train, DT_test, Class_train, Class_test = train_test_split(DT, Class, test_size=0.2, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters.T[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Class_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Completenness Score is ', 0.831410599743451)\n",
      "('Homogeneity Score is ', 0.831255162573729)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import completeness_score, homogeneity_score\n",
    "predict_Class_train_=clusters.T[0]\n",
    "print('Completenness Score is ',completeness_score(Class_train , predict_Class_train_))\n",
    "print('Homogeneity Score is ',homogeneity_score(Class_train , predict_Class_train_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baed on the result, the completenness score is quite high which means that most of the data points are members of a given class are assigned to the same cluster. The Homogeneity Score are as high as the completenness score. In this case, it represent about 83.7% of clusters do not only contain the members of data points belong to one Single cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e. Finally, using your cluster assignments as class labels, categorize each of the documents in the 20% set-aside data into each of the appropriate cluster. Your categorization should be based on Cosine similarity between each test document and cluster centroids. For each test document show the predicted class label as well as Cosine similarity to the corresponding cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity With Cluster 1</th>\n",
       "      <th>Similarity With Cluster 2</th>\n",
       "      <th>Similarity With Cluster 3</th>\n",
       "      <th>Similarity With Cluster 4</th>\n",
       "      <th>Similarity With Cluster 5</th>\n",
       "      <th>Cluster Assignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060551</td>\n",
       "      <td>0.045611</td>\n",
       "      <td>0.045606</td>\n",
       "      <td>0.148978</td>\n",
       "      <td>0.042910</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.101560</td>\n",
       "      <td>0.065623</td>\n",
       "      <td>0.063095</td>\n",
       "      <td>0.162041</td>\n",
       "      <td>0.082199</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.033958</td>\n",
       "      <td>0.025975</td>\n",
       "      <td>0.023437</td>\n",
       "      <td>0.037503</td>\n",
       "      <td>0.106480</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.132757</td>\n",
       "      <td>0.109677</td>\n",
       "      <td>0.296690</td>\n",
       "      <td>0.136764</td>\n",
       "      <td>0.105167</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.026766</td>\n",
       "      <td>0.093297</td>\n",
       "      <td>0.033020</td>\n",
       "      <td>0.059599</td>\n",
       "      <td>0.207182</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.436565</td>\n",
       "      <td>0.103924</td>\n",
       "      <td>0.112584</td>\n",
       "      <td>0.125249</td>\n",
       "      <td>0.109056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.128532</td>\n",
       "      <td>0.332148</td>\n",
       "      <td>0.101132</td>\n",
       "      <td>0.134792</td>\n",
       "      <td>0.094342</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.074624</td>\n",
       "      <td>0.049821</td>\n",
       "      <td>0.057916</td>\n",
       "      <td>0.090390</td>\n",
       "      <td>0.096512</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.119753</td>\n",
       "      <td>0.105476</td>\n",
       "      <td>0.097094</td>\n",
       "      <td>0.464692</td>\n",
       "      <td>0.093785</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.053651</td>\n",
       "      <td>0.064825</td>\n",
       "      <td>0.054491</td>\n",
       "      <td>0.128654</td>\n",
       "      <td>0.041227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Similarity With Cluster 1  Similarity With Cluster 2  \\\n",
       "0                   0.060551                   0.045611   \n",
       "1                   0.101560                   0.065623   \n",
       "2                   0.033958                   0.025975   \n",
       "3                   0.132757                   0.109677   \n",
       "4                   0.026766                   0.093297   \n",
       "5                   0.436565                   0.103924   \n",
       "6                   0.128532                   0.332148   \n",
       "7                   0.074624                   0.049821   \n",
       "8                   0.119753                   0.105476   \n",
       "9                   0.053651                   0.064825   \n",
       "\n",
       "   Similarity With Cluster 3  Similarity With Cluster 4  \\\n",
       "0                   0.045606                   0.148978   \n",
       "1                   0.063095                   0.162041   \n",
       "2                   0.023437                   0.037503   \n",
       "3                   0.296690                   0.136764   \n",
       "4                   0.033020                   0.059599   \n",
       "5                   0.112584                   0.125249   \n",
       "6                   0.101132                   0.134792   \n",
       "7                   0.057916                   0.090390   \n",
       "8                   0.097094                   0.464692   \n",
       "9                   0.054491                   0.128654   \n",
       "\n",
       "   Similarity With Cluster 5  Cluster Assignment  \n",
       "0                   0.042910                   4  \n",
       "1                   0.082199                   4  \n",
       "2                   0.106480                   5  \n",
       "3                   0.105167                   3  \n",
       "4                   0.207182                   5  \n",
       "5                   0.109056                   1  \n",
       "6                   0.094342                   2  \n",
       "7                   0.096512                   5  \n",
       "8                   0.093785                   4  \n",
       "9                   0.041227                   4  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "for test_doc in NewDTTest_TFIDF:\n",
    "    dic = {}\n",
    "    sim = []\n",
    "    cluster=1\n",
    "    for centroid in centroids:\n",
    "        sim.append(1-disCosine(test_doc, centroid)) \n",
    "        dic['Similarity With Cluster '+str(cluster)] = 1 - disCosine(test_doc, centroid)\n",
    "        cluster+=1\n",
    "    dic['Cluster Assignment'] = sim.index(max(sim))+1\n",
    "    records.append(dic)\n",
    "test_cluster = pd.DataFrame(records,index=range(len(NewDTTest_TFIDF)),columns=['Similarity With Cluster 1','Similarity With Cluster 2',\n",
    "                                                                             'Similarity With Cluster 3','Similarity With Cluster 4',\n",
    "                                                                             'Similarity With Cluster 5', 'Cluster Assignment'])\n",
    "test_cluster.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cluster.to_csv('test_cluster.csv', sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
